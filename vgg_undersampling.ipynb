{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_undersampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3M2_cNlY6ew"
      },
      "source": [
        "USING VGG MODEL ,  WITH UNDERSAMPLING AND DATA AUGMENTATION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential\n",
        "import io\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGwx0ao7ZDIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86701987-aac0-4f8e-8c47-d9c553d8b151"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJbW3kPmZKJ4"
      },
      "source": [
        "dataset=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/fer2013.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hfQswg-ZMQH"
      },
      "source": [
        "def convert_pixels_to_img(pixels):\n",
        "    test_image = pixels.reshape(48,48,1)\n",
        "    return test_image\n",
        "\n",
        "def split_pixels(string):\n",
        "    splitted = np.array(string.split(),'int')\n",
        "    return splitted \n",
        "\n",
        "def change_to_categorical(sample):\n",
        "    return keras.utils.to_categorical(sample,num_classes=7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dKsIKa-ZOQQ"
      },
      "source": [
        "dataset['pixels'] = dataset['pixels'].apply(split_pixels)\n",
        "dataset['label'] = dataset['emotion'].apply(change_to_categorical)\n",
        "dataset['length'] = dataset['pixels'].apply(len)\n",
        "\n",
        "dataset = dataset[dataset.length == 2304]\n",
        "dataset['image'] = dataset['pixels'].apply(convert_pixels_to_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRDoB_fcZRSn"
      },
      "source": [
        "grouped_dataset = dataset.groupby(dataset.Usage)\n",
        "training_dataset = grouped_dataset.get_group(\"Training\")\n",
        "dev_dataset = grouped_dataset.get_group(\"PublicTest\")\n",
        "test_dataset = grouped_dataset.get_group(\"PrivateTest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mirOkU8XZTsm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d7c35a09-8360-4925-a8ec-7627ba9956a6"
      },
      "source": [
        "training_dataset = training_dataset.loc[training_dataset[\"emotion\"]!=1]\n",
        "dev_dataset = dev_dataset.loc[dev_dataset[\"emotion\"]!=1]\n",
        "test_dataset = test_dataset.loc[test_dataset[\"emotion\"]!=1]\n",
        "def balancingDataset(x):\n",
        "  new_df=training_dataset.loc[dataset['emotion']==x]\n",
        "  new_df=new_df[:3000]\n",
        "  return new_df\n",
        "df_0=balancingDataset(0)\n",
        "df_2=balancingDataset(2)\n",
        "df_3=balancingDataset(3)\n",
        "df_4=balancingDataset(4)\n",
        "df_5=balancingDataset(5)\n",
        "df_6=balancingDataset(6)\n",
        "\n",
        "\n",
        "training_dataset=pd.concat([df_0,df_2,df_3,df_4,df_5,df_6])\n",
        "training_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "      <th>label</th>\n",
              "      <th>length</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[70, 80, 82, 72, 58, 58, 60, 63, 54, 58, 60, 4...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[70], [80], [82], [72], [58], [58], [60], [6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[151, 150, 147, 155, 148, 133, 111, 140, 170, ...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[151], [150], [147], [155], [148], [133], [1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>[30, 24, 21, 23, 25, 25, 49, 67, 84, 103, 120,...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[30], [24], [21], [23], [25], [25], [49], [6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>[123, 125, 124, 142, 209, 226, 234, 236, 231, ...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[123], [125], [124], [142], [209], [226], [2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>[8, 9, 14, 21, 26, 32, 37, 46, 52, 62, 72, 70,...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[8], [9], [14], [21], [26], [32], [37], [46]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17073</th>\n",
              "      <td>6</td>\n",
              "      <td>[101, 105, 136, 141, 165, 167, 164, 170, 170, ...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[101], [105], [136], [141], [165], [167], [1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17075</th>\n",
              "      <td>6</td>\n",
              "      <td>[116, 131, 120, 84, 43, 55, 58, 61, 61, 66, 70...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[116], [131], [120], [84], [43], [55], [58],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17081</th>\n",
              "      <td>6</td>\n",
              "      <td>[255, 255, 254, 254, 254, 254, 254, 255, 255, ...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[255], [255], [254], [254], [254], [254], [2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17082</th>\n",
              "      <td>6</td>\n",
              "      <td>[50, 52, 50, 49, 44, 51, 51, 41, 33, 39, 43, 4...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[50], [52], [50], [49], [44], [51], [51], [4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17083</th>\n",
              "      <td>6</td>\n",
              "      <td>[152, 136, 55, 31, 32, 28, 34, 36, 40, 49, 63,...</td>\n",
              "      <td>Training</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[152], [136], [55], [31], [32], [28], [34], ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion  ...                                              image\n",
              "0            0  ...  [[[70], [80], [82], [72], [58], [58], [60], [6...\n",
              "1            0  ...  [[[151], [150], [147], [155], [148], [133], [1...\n",
              "10           0  ...  [[[30], [24], [21], [23], [25], [25], [49], [6...\n",
              "22           0  ...  [[[123], [125], [124], [142], [209], [226], [2...\n",
              "23           0  ...  [[[8], [9], [14], [21], [26], [32], [37], [46]...\n",
              "...        ...  ...                                                ...\n",
              "17073        6  ...  [[[101], [105], [136], [141], [165], [167], [1...\n",
              "17075        6  ...  [[[116], [131], [120], [84], [43], [55], [58],...\n",
              "17081        6  ...  [[[255], [255], [254], [254], [254], [254], [2...\n",
              "17082        6  ...  [[[50], [52], [50], [49], [44], [51], [51], [4...\n",
              "17083        6  ...  [[[152], [136], [55], [31], [32], [28], [34], ...\n",
              "\n",
              "[18000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj0satDLZV8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "03963595-2abe-4fd1-e323-63e2563573b9"
      },
      "source": [
        "dev_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "      <th>label</th>\n",
              "      <th>length</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28709</th>\n",
              "      <td>0</td>\n",
              "      <td>[254, 254, 254, 254, 254, 249, 255, 160, 2, 58...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[254], [254], [254], [254], [254], [249], [2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28711</th>\n",
              "      <td>4</td>\n",
              "      <td>[69, 118, 61, 60, 96, 121, 103, 87, 103, 88, 7...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[69], [118], [61], [60], [96], [121], [103],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28712</th>\n",
              "      <td>6</td>\n",
              "      <td>[205, 203, 236, 157, 83, 158, 120, 116, 94, 86...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[205], [203], [236], [157], [83], [158], [12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28713</th>\n",
              "      <td>3</td>\n",
              "      <td>[87, 79, 74, 66, 74, 96, 77, 80, 80, 84, 83, 8...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[87], [79], [74], [66], [74], [96], [77], [8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28714</th>\n",
              "      <td>3</td>\n",
              "      <td>[235, 233, 223, 109, 34, 37, 34, 31, 28, 38, 5...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[235], [233], [223], [109], [34], [37], [34]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32293</th>\n",
              "      <td>4</td>\n",
              "      <td>[178, 176, 172, 173, 173, 174, 176, 173, 166, ...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[178], [176], [172], [173], [173], [174], [1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32294</th>\n",
              "      <td>3</td>\n",
              "      <td>[25, 34, 42, 44, 42, 47, 57, 59, 59, 58, 54, 5...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[25], [34], [42], [44], [42], [47], [57], [5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32295</th>\n",
              "      <td>4</td>\n",
              "      <td>[255, 255, 255, 255, 255, 255, 255, 255, 255, ...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[255], [255], [255], [255], [255], [255], [2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32296</th>\n",
              "      <td>4</td>\n",
              "      <td>[33, 25, 31, 36, 36, 42, 69, 103, 132, 163, 17...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[33], [25], [31], [36], [36], [42], [69], [1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32297</th>\n",
              "      <td>4</td>\n",
              "      <td>[61, 63, 59, 75, 151, 159, 166, 161, 143, 170,...</td>\n",
              "      <td>PublicTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[61], [63], [59], [75], [151], [159], [166],...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3533 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion  ...                                              image\n",
              "28709        0  ...  [[[254], [254], [254], [254], [254], [249], [2...\n",
              "28711        4  ...  [[[69], [118], [61], [60], [96], [121], [103],...\n",
              "28712        6  ...  [[[205], [203], [236], [157], [83], [158], [12...\n",
              "28713        3  ...  [[[87], [79], [74], [66], [74], [96], [77], [8...\n",
              "28714        3  ...  [[[235], [233], [223], [109], [34], [37], [34]...\n",
              "...        ...  ...                                                ...\n",
              "32293        4  ...  [[[178], [176], [172], [173], [173], [174], [1...\n",
              "32294        3  ...  [[[25], [34], [42], [44], [42], [47], [57], [5...\n",
              "32295        4  ...  [[[255], [255], [255], [255], [255], [255], [2...\n",
              "32296        4  ...  [[[33], [25], [31], [36], [36], [42], [69], [1...\n",
              "32297        4  ...  [[[61], [63], [59], [75], [151], [159], [166],...\n",
              "\n",
              "[3533 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z66Z2d0wZX0q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "2d30d64e-868b-4e98-d60b-88e49bc0689f"
      },
      "source": [
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "      <th>label</th>\n",
              "      <th>length</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32298</th>\n",
              "      <td>0</td>\n",
              "      <td>[170, 118, 101, 88, 88, 75, 78, 82, 66, 74, 68...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[170], [118], [101], [88], [88], [75], [78],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32299</th>\n",
              "      <td>5</td>\n",
              "      <td>[7, 5, 8, 6, 7, 3, 2, 6, 5, 4, 4, 5, 7, 5, 5, ...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[7], [5], [8], [6], [7], [3], [2], [6], [5],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32300</th>\n",
              "      <td>6</td>\n",
              "      <td>[232, 240, 241, 239, 237, 235, 246, 117, 24, 2...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[232], [240], [241], [239], [237], [235], [2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32301</th>\n",
              "      <td>4</td>\n",
              "      <td>[200, 197, 149, 139, 156, 89, 111, 58, 62, 95,...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[200], [197], [149], [139], [156], [89], [11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32302</th>\n",
              "      <td>2</td>\n",
              "      <td>[40, 28, 33, 56, 45, 33, 31, 78, 152, 194, 200...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[40], [28], [33], [56], [45], [33], [31], [7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>6</td>\n",
              "      <td>[50, 36, 17, 22, 23, 29, 33, 39, 34, 37, 37, 3...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[50], [36], [17], [22], [23], [29], [33], [3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35883</th>\n",
              "      <td>3</td>\n",
              "      <td>[178, 174, 172, 173, 181, 188, 191, 194, 196, ...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[178], [174], [172], [173], [181], [188], [1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35884</th>\n",
              "      <td>0</td>\n",
              "      <td>[17, 17, 16, 23, 28, 22, 19, 17, 25, 26, 20, 2...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[17], [17], [16], [23], [28], [22], [19], [1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35885</th>\n",
              "      <td>3</td>\n",
              "      <td>[30, 28, 28, 29, 31, 30, 42, 68, 79, 81, 77, 6...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[30], [28], [28], [29], [31], [30], [42], [6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35886</th>\n",
              "      <td>2</td>\n",
              "      <td>[19, 13, 14, 12, 13, 16, 21, 33, 50, 57, 71, 8...</td>\n",
              "      <td>PrivateTest</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2304</td>\n",
              "      <td>[[[19], [13], [14], [12], [13], [16], [21], [3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3534 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion  ...                                              image\n",
              "32298        0  ...  [[[170], [118], [101], [88], [88], [75], [78],...\n",
              "32299        5  ...  [[[7], [5], [8], [6], [7], [3], [2], [6], [5],...\n",
              "32300        6  ...  [[[232], [240], [241], [239], [237], [235], [2...\n",
              "32301        4  ...  [[[200], [197], [149], [139], [156], [89], [11...\n",
              "32302        2  ...  [[[40], [28], [33], [56], [45], [33], [31], [7...\n",
              "...        ...  ...                                                ...\n",
              "35882        6  ...  [[[50], [36], [17], [22], [23], [29], [33], [3...\n",
              "35883        3  ...  [[[178], [174], [172], [173], [181], [188], [1...\n",
              "35884        0  ...  [[[17], [17], [16], [23], [28], [22], [19], [1...\n",
              "35885        3  ...  [[[30], [28], [28], [29], [31], [30], [42], [6...\n",
              "35886        2  ...  [[[19], [13], [14], [12], [13], [16], [21], [3...\n",
              "\n",
              "[3534 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY0_chv7Za48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d9a7b4-3023-4bb4-a886-fa76ef84da72"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(input_shape=(48,48,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=4096,activation=\"relu\"))\n",
        "model.add(layers.Dense(units=4096,activation=\"relu\"))\n",
        "model.add(layers.Dense(units=7, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 33,624,775\n",
            "Trainable params: 33,624,775\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D15bI-8RZdo-"
      },
      "source": [
        "x_train = training_dataset['image']\n",
        "y_train = training_dataset['label']\n",
        "x_test =  dev_dataset['image']\n",
        "y_test = dev_dataset['label']\n",
        "\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "\n",
        "x_train = np.stack(x_train,axis=0)\n",
        "y_train = np.stack(y_train,axis=0)\n",
        "x_test = np.stack(x_test,axis=0)\n",
        "y_test = np.stack(y_test,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F5IQjIqZf_0"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eP0e6nkZirP"
      },
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=5)\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, mode='auto')\n",
        "checkpointer = ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5', monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29re18zXZuDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a55ffd-ed4b-4ddb-c90e-f466367c14c1"
      },
      "source": [
        "model.fit(datagen.flow(x_train, y_train, batch_size=32),batch_size=32,epochs=100,verbose=1,callbacks=[checkpointer,lr_reducer,early_stopper],validation_data=(x_test, y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "563/563 [==============================] - 46s 26ms/step - loss: 1.8204 - accuracy: 0.1756 - val_loss: 1.7602 - val_accuracy: 0.2454\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.76020, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 2/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.7774 - accuracy: 0.2128 - val_loss: 1.7298 - val_accuracy: 0.2559\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.76020 to 1.72979, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 3/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.7429 - accuracy: 0.2499 - val_loss: 1.7493 - val_accuracy: 0.2734\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.72979\n",
            "Epoch 4/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.6803 - accuracy: 0.2938 - val_loss: 1.5852 - val_accuracy: 0.3937\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.72979 to 1.58520, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 5/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.6268 - accuracy: 0.3297 - val_loss: 1.5213 - val_accuracy: 0.4005\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.58520 to 1.52131, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 6/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.5781 - accuracy: 0.3518 - val_loss: 1.4823 - val_accuracy: 0.4073\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.52131 to 1.48233, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 7/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.5390 - accuracy: 0.3715 - val_loss: 1.3981 - val_accuracy: 0.4520\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.48233 to 1.39812, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 8/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.5076 - accuracy: 0.3903 - val_loss: 1.4111 - val_accuracy: 0.4452\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.39812\n",
            "Epoch 9/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.4720 - accuracy: 0.4125 - val_loss: 1.4226 - val_accuracy: 0.4356\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.39812\n",
            "Epoch 10/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.4356 - accuracy: 0.4260 - val_loss: 1.3222 - val_accuracy: 0.4860\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.39812 to 1.32217, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 11/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.3967 - accuracy: 0.4456 - val_loss: 1.2857 - val_accuracy: 0.4990\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.32217 to 1.28574, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 12/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.3721 - accuracy: 0.4542 - val_loss: 1.3334 - val_accuracy: 0.4829\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.28574\n",
            "Epoch 13/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.3404 - accuracy: 0.4674 - val_loss: 1.2242 - val_accuracy: 0.5321\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.28574 to 1.22421, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 14/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.3188 - accuracy: 0.4737 - val_loss: 1.1912 - val_accuracy: 0.5415\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.22421 to 1.19117, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 15/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.2716 - accuracy: 0.4993 - val_loss: 1.2190 - val_accuracy: 0.5222\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.19117\n",
            "Epoch 16/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.2358 - accuracy: 0.5163 - val_loss: 1.1675 - val_accuracy: 0.5525\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.19117 to 1.16746, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 17/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.2191 - accuracy: 0.5247 - val_loss: 1.1492 - val_accuracy: 0.5556\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.16746 to 1.14922, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 18/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.2098 - accuracy: 0.5221 - val_loss: 1.1980 - val_accuracy: 0.5420\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.14922\n",
            "Epoch 19/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.1801 - accuracy: 0.5380 - val_loss: 1.1330 - val_accuracy: 0.5703\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.14922 to 1.13297, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 20/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.1681 - accuracy: 0.5430 - val_loss: 1.1775 - val_accuracy: 0.5460\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.13297\n",
            "Epoch 21/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.1352 - accuracy: 0.5575 - val_loss: 1.1412 - val_accuracy: 0.5505\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.13297\n",
            "Epoch 22/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.1330 - accuracy: 0.5665 - val_loss: 1.1370 - val_accuracy: 0.5667\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.13297\n",
            "Epoch 23/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.1098 - accuracy: 0.5743 - val_loss: 1.0972 - val_accuracy: 0.5853\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.13297 to 1.09720, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 24/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0893 - accuracy: 0.5759 - val_loss: 1.1657 - val_accuracy: 0.5593\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.09720\n",
            "Epoch 25/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0787 - accuracy: 0.5822 - val_loss: 1.0953 - val_accuracy: 0.5907\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.09720 to 1.09526, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 26/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0789 - accuracy: 0.5837 - val_loss: 1.1301 - val_accuracy: 0.5811\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.09526\n",
            "Epoch 27/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0502 - accuracy: 0.5989 - val_loss: 1.0506 - val_accuracy: 0.6003\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.09526 to 1.05062, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 28/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0544 - accuracy: 0.5951 - val_loss: 1.0762 - val_accuracy: 0.5927\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.05062\n",
            "Epoch 29/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0321 - accuracy: 0.5974 - val_loss: 1.2058 - val_accuracy: 0.5508\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.05062\n",
            "Epoch 30/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0268 - accuracy: 0.6041 - val_loss: 1.0842 - val_accuracy: 0.5998\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.05062\n",
            "Epoch 31/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 1.0080 - accuracy: 0.6166 - val_loss: 1.0467 - val_accuracy: 0.6148\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.05062 to 1.04674, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 32/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9866 - accuracy: 0.6263 - val_loss: 1.0903 - val_accuracy: 0.5955\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.04674\n",
            "Epoch 33/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9888 - accuracy: 0.6226 - val_loss: 1.0484 - val_accuracy: 0.6102\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.04674\n",
            "Epoch 34/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9737 - accuracy: 0.6243 - val_loss: 1.0718 - val_accuracy: 0.6162\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.04674\n",
            "Epoch 35/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9626 - accuracy: 0.6311 - val_loss: 1.1185 - val_accuracy: 0.5947\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.04674\n",
            "Epoch 36/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9481 - accuracy: 0.6338 - val_loss: 1.0597 - val_accuracy: 0.6066\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.04674\n",
            "Epoch 37/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9342 - accuracy: 0.6415 - val_loss: 1.0892 - val_accuracy: 0.6117\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.04674\n",
            "Epoch 38/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9173 - accuracy: 0.6496 - val_loss: 1.0633 - val_accuracy: 0.6080\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.04674\n",
            "Epoch 39/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.9141 - accuracy: 0.6485 - val_loss: 1.0744 - val_accuracy: 0.6091\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.04674\n",
            "Epoch 40/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8941 - accuracy: 0.6573 - val_loss: 1.1007 - val_accuracy: 0.5961\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.04674\n",
            "Epoch 41/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8982 - accuracy: 0.6514 - val_loss: 1.0313 - val_accuracy: 0.6275\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.04674 to 1.03132, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 42/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8777 - accuracy: 0.6638 - val_loss: 1.0276 - val_accuracy: 0.6179\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.03132 to 1.02756, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 43/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8706 - accuracy: 0.6705 - val_loss: 1.0396 - val_accuracy: 0.6284\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.02756\n",
            "Epoch 44/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8651 - accuracy: 0.6730 - val_loss: 1.0465 - val_accuracy: 0.6077\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.02756\n",
            "Epoch 45/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8544 - accuracy: 0.6682 - val_loss: 1.1150 - val_accuracy: 0.6083\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.02756\n",
            "Epoch 46/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8554 - accuracy: 0.6735 - val_loss: 1.1410 - val_accuracy: 0.5995\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.02756\n",
            "Epoch 47/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8359 - accuracy: 0.6782 - val_loss: 1.0171 - val_accuracy: 0.6289\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.02756 to 1.01713, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 48/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8396 - accuracy: 0.6819 - val_loss: 1.0024 - val_accuracy: 0.6309\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.01713 to 1.00243, saving model to /content/gdrive/My Drive/Colab Notebooks/Emotion Recognition/Model/vgg_undersampling.h5\n",
            "Epoch 49/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.8352 - accuracy: 0.6798 - val_loss: 1.0393 - val_accuracy: 0.6131\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.00243\n",
            "Epoch 50/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7920 - accuracy: 0.6981 - val_loss: 1.0378 - val_accuracy: 0.6264\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.00243\n",
            "Epoch 51/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7969 - accuracy: 0.6971 - val_loss: 1.0370 - val_accuracy: 0.6151\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.00243\n",
            "Epoch 52/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7970 - accuracy: 0.6943 - val_loss: 1.0525 - val_accuracy: 0.6309\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.00243\n",
            "Epoch 53/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7908 - accuracy: 0.6975 - val_loss: 1.0755 - val_accuracy: 0.6269\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.00243\n",
            "Epoch 54/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7728 - accuracy: 0.7046 - val_loss: 1.0431 - val_accuracy: 0.6363\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.00243\n",
            "Epoch 55/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7469 - accuracy: 0.7196 - val_loss: 1.0609 - val_accuracy: 0.6303\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.00243\n",
            "Epoch 56/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7377 - accuracy: 0.7221 - val_loss: 1.1452 - val_accuracy: 0.6165\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.00243\n",
            "Epoch 57/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7347 - accuracy: 0.7213 - val_loss: 1.2627 - val_accuracy: 0.5856\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.00243\n",
            "Epoch 58/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7149 - accuracy: 0.7254 - val_loss: 1.0855 - val_accuracy: 0.6272\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.00243\n",
            "Epoch 59/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6956 - accuracy: 0.7345 - val_loss: 1.1416 - val_accuracy: 0.6306\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.00243\n",
            "Epoch 60/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.7017 - accuracy: 0.7324 - val_loss: 1.1393 - val_accuracy: 0.6315\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.00243\n",
            "Epoch 61/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6723 - accuracy: 0.7473 - val_loss: 1.1135 - val_accuracy: 0.6241\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.00243\n",
            "Epoch 62/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6660 - accuracy: 0.7485 - val_loss: 1.0906 - val_accuracy: 0.6340\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.00243\n",
            "Epoch 63/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6675 - accuracy: 0.7470 - val_loss: 1.1039 - val_accuracy: 0.6337\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.00243\n",
            "Epoch 64/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6517 - accuracy: 0.7524 - val_loss: 1.1046 - val_accuracy: 0.6417\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.00243\n",
            "Epoch 65/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6221 - accuracy: 0.7696 - val_loss: 1.1885 - val_accuracy: 0.6213\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.00243\n",
            "Epoch 66/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6378 - accuracy: 0.7608 - val_loss: 1.1267 - val_accuracy: 0.6329\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.00243\n",
            "Epoch 67/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6224 - accuracy: 0.7656 - val_loss: 1.1422 - val_accuracy: 0.6354\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.00243\n",
            "Epoch 68/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.6164 - accuracy: 0.7689 - val_loss: 1.1744 - val_accuracy: 0.6386\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.00243\n",
            "Epoch 69/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5861 - accuracy: 0.7826 - val_loss: 1.2138 - val_accuracy: 0.6329\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.00243\n",
            "Epoch 70/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5855 - accuracy: 0.7780 - val_loss: 1.1413 - val_accuracy: 0.6436\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.00243\n",
            "Epoch 71/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5711 - accuracy: 0.7894 - val_loss: 1.1950 - val_accuracy: 0.6383\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.00243\n",
            "Epoch 72/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5608 - accuracy: 0.7924 - val_loss: 1.1165 - val_accuracy: 0.6456\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.00243\n",
            "Epoch 73/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5637 - accuracy: 0.7920 - val_loss: 1.1862 - val_accuracy: 0.6431\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.00243\n",
            "Epoch 74/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5404 - accuracy: 0.7933 - val_loss: 1.2045 - val_accuracy: 0.6357\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.00243\n",
            "Epoch 75/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5259 - accuracy: 0.8077 - val_loss: 1.2408 - val_accuracy: 0.6482\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.00243\n",
            "Epoch 76/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5216 - accuracy: 0.8071 - val_loss: 1.2281 - val_accuracy: 0.6357\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.00243\n",
            "Epoch 77/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5163 - accuracy: 0.8061 - val_loss: 1.2191 - val_accuracy: 0.6462\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.00243\n",
            "Epoch 78/100\n",
            "563/563 [==============================] - 14s 25ms/step - loss: 0.5146 - accuracy: 0.8088 - val_loss: 1.2284 - val_accuracy: 0.6476\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.00243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3456112310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gECrBIIVfBpb"
      },
      "source": [
        "x_test =  test_dataset['image']\n",
        "y_test = test_dataset['label']\n",
        "\n",
        "#Pandas dataframe to numpy\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "#numpy array reshape to fit into model\n",
        "x_test = np.stack(x_test,axis=0)\n",
        "y_test = np.stack(y_test,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR-lkx6wfHhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e22d2d-fda6-41f9-d21b-a53e7992b9bc"
      },
      "source": [
        "model.evaluate(x_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 10ms/step - loss: 1.1587 - accuracy: 0.6531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1586873531341553, 0.6530843377113342]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}