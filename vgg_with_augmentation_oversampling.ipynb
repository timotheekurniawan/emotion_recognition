{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_with_augmentation_oversampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3JbMJD+wLVTyYBzHIFSt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timotheekurniawan/emotion_recognition/blob/master/vgg_with_augmentation_oversampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em6XfjkJWPEB"
      },
      "source": [
        "USING VGG MODEL ,  WITH OVERSAMPLING AND DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR49j8g-_clz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential\n",
        "import io\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import resample\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHJ8Zh6F_hNl",
        "outputId": "67bd9078-ec47-47b1-ee6b-0818bec75e29"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmxEsfAT_nIe"
      },
      "source": [
        "dataset=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/fer2013.csv\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "gLn1h-XU_s6Y",
        "outputId": "d620ca9e-d007-4794-b3ce-7e41d5cbc981"
      },
      "source": [
        "dataset = dataset.loc[dataset[\"emotion\"]!=1]\n",
        "def balancingDataset(x):\n",
        "  new_df=dataset.loc[dataset['emotion']==x]\n",
        "  data_to_add=9000-len(new_df)\n",
        "  random_sampling=resample(new_df,random_state=42,replace=True,n_samples=data_to_add)\n",
        "  return pd.concat([new_df,random_sampling])\n",
        "\n",
        "df_0=balancingDataset(0)\n",
        "df_2=balancingDataset(2)\n",
        "df_3=balancingDataset(3)\n",
        "df_4=balancingDataset(4)\n",
        "df_5=balancingDataset(5)\n",
        "df_6=balancingDataset(6)\n",
        "\n",
        "\n",
        "dataset=pd.concat([df_0,df_2,df_3,df_4,df_5,df_6])\n",
        "dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>30 24 21 23 25 25 49 67 84 103 120 125 130 139...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>123 125 124 142 209 226 234 236 231 232 235 22...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33468</th>\n",
              "      <td>6</td>\n",
              "      <td>75 96 96 51 50 48 30 27 19 22 20 11 16 23 75 1...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26433</th>\n",
              "      <td>6</td>\n",
              "      <td>47 45 52 45 4 8 2 11 40 59 68 41 14 32 51 78 5...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34343</th>\n",
              "      <td>6</td>\n",
              "      <td>23 14 14 9 29 30 35 43 32 47 46 57 67 78 96 98...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28551</th>\n",
              "      <td>6</td>\n",
              "      <td>99 105 107 113 115 116 120 121 123 133 120 109...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21404</th>\n",
              "      <td>6</td>\n",
              "      <td>170 183 172 188 177 172 174 180 187 191 192 19...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels        Usage\n",
              "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
              "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
              "10           0  30 24 21 23 25 25 49 67 84 103 120 125 130 139...     Training\n",
              "22           0  123 125 124 142 209 226 234 236 231 232 235 22...     Training\n",
              "23           0  8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...     Training\n",
              "...        ...                                                ...          ...\n",
              "33468        6  75 96 96 51 50 48 30 27 19 22 20 11 16 23 75 1...  PrivateTest\n",
              "26433        6  47 45 52 45 4 8 2 11 40 59 68 41 14 32 51 78 5...     Training\n",
              "34343        6  23 14 14 9 29 30 35 43 32 47 46 57 67 78 96 98...  PrivateTest\n",
              "28551        6  99 105 107 113 115 116 120 121 123 133 120 109...     Training\n",
              "21404        6  170 183 172 188 177 172 174 180 187 191 192 19...     Training\n",
              "\n",
              "[54000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebKufpwX_vrZ"
      },
      "source": [
        "def convert_pixels_to_img(pixels):\n",
        "    test_image = pixels.reshape(48,48,1)\n",
        "    return test_image\n",
        "\n",
        "def split_pixels(string):\n",
        "    splitted = np.array(string.split(),'int')\n",
        "    return splitted \n",
        "\n",
        "def change_to_categorical(sample):\n",
        "    return keras.utils.to_categorical(sample,num_classes=7)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGcpYQ1w_xlz"
      },
      "source": [
        "dataset['pixels'] = dataset['pixels'].apply(split_pixels)\n",
        "dataset['label'] = dataset['emotion'].apply(change_to_categorical)\n",
        "dataset['length'] = dataset['pixels'].apply(len)\n",
        "\n",
        "dataset = dataset[dataset.length == 2304]\n",
        "dataset['image'] = dataset['pixels'].apply(convert_pixels_to_img)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWC99_0u_0ST"
      },
      "source": [
        "grouped_dataset = dataset.groupby(dataset.Usage)\n",
        "training_dataset = grouped_dataset.get_group(\"Training\")\n",
        "dev_dataset = grouped_dataset.get_group(\"PublicTest\")\n",
        "test_dataset = grouped_dataset.get_group(\"PrivateTest\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dweMx6KK_3FG",
        "outputId": "935180f4-3132-48b6-9f52-248679332a9d"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(input_shape=(48,48,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=4096,activation=\"relu\"))\n",
        "model.add(layers.Dense(units=4096,activation=\"relu\"))\n",
        "model.add(layers.Dense(units=7, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 33,624,775\n",
            "Trainable params: 33,624,775\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPy_oZDd_52k"
      },
      "source": [
        "x_train = training_dataset['image']\n",
        "y_train = training_dataset['label']\n",
        "x_test =  dev_dataset['image']\n",
        "y_test = dev_dataset['label']\n",
        "\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "\n",
        "x_train = np.stack(x_train,axis=0)\n",
        "y_train = np.stack(y_train,axis=0)\n",
        "x_test = np.stack(x_test,axis=0)\n",
        "y_test = np.stack(y_test,axis=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxsMHbLOFRx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab37e278-354f-4e79-f5f5-dcdd4d70e7d7"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "generator=datagen.flow(x_train,y_train,batch_size=32)\n",
        "print(generator.__len__())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmIc6UAR_8-Y",
        "outputId": "fa474628-73d3-469e-8645-8798c4dc7c78"
      },
      "source": [
        "model.fit(datagen.flow(x_train, y_train, batch_size=32),batch_size=32,epochs=150,verbose=1,validation_data=(x_test, y_test))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1351/1351 [==============================] - 67s 27ms/step - loss: 1.8046 - accuracy: 0.1838 - val_loss: 1.7223 - val_accuracy: 0.2536\n",
            "Epoch 2/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.7010 - accuracy: 0.2792 - val_loss: 1.5170 - val_accuracy: 0.3966\n",
            "Epoch 3/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.5718 - accuracy: 0.3547 - val_loss: 1.4125 - val_accuracy: 0.4438\n",
            "Epoch 4/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.4581 - accuracy: 0.4129 - val_loss: 1.4313 - val_accuracy: 0.4403\n",
            "Epoch 5/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.3612 - accuracy: 0.4570 - val_loss: 1.2713 - val_accuracy: 0.5067\n",
            "Epoch 6/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.2760 - accuracy: 0.4969 - val_loss: 1.2489 - val_accuracy: 0.5219\n",
            "Epoch 7/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.2137 - accuracy: 0.5235 - val_loss: 1.1986 - val_accuracy: 0.5350\n",
            "Epoch 8/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.1735 - accuracy: 0.5415 - val_loss: 1.1680 - val_accuracy: 0.5515\n",
            "Epoch 9/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.1182 - accuracy: 0.5677 - val_loss: 1.0978 - val_accuracy: 0.5857\n",
            "Epoch 10/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.0957 - accuracy: 0.5732 - val_loss: 1.1047 - val_accuracy: 0.5855\n",
            "Epoch 11/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 1.0594 - accuracy: 0.5898 - val_loss: 1.0824 - val_accuracy: 0.5942\n",
            "Epoch 12/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 1.0348 - accuracy: 0.6004 - val_loss: 1.1192 - val_accuracy: 0.5825\n",
            "Epoch 13/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 1.0112 - accuracy: 0.6133 - val_loss: 1.0217 - val_accuracy: 0.6149\n",
            "Epoch 14/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.9853 - accuracy: 0.6249 - val_loss: 1.1164 - val_accuracy: 0.5899\n",
            "Epoch 15/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.9591 - accuracy: 0.6341 - val_loss: 1.0205 - val_accuracy: 0.6188\n",
            "Epoch 16/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.9400 - accuracy: 0.6423 - val_loss: 1.0402 - val_accuracy: 0.6127\n",
            "Epoch 17/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.9233 - accuracy: 0.6532 - val_loss: 1.0738 - val_accuracy: 0.5882\n",
            "Epoch 18/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.9100 - accuracy: 0.6549 - val_loss: 1.0114 - val_accuracy: 0.6127\n",
            "Epoch 19/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.8896 - accuracy: 0.6674 - val_loss: 0.9990 - val_accuracy: 0.6257\n",
            "Epoch 20/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.8672 - accuracy: 0.6710 - val_loss: 1.0229 - val_accuracy: 0.6151\n",
            "Epoch 21/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.8415 - accuracy: 0.6843 - val_loss: 1.0651 - val_accuracy: 0.6175\n",
            "Epoch 22/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.8307 - accuracy: 0.6901 - val_loss: 1.0153 - val_accuracy: 0.6174\n",
            "Epoch 23/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.8183 - accuracy: 0.6915 - val_loss: 1.0516 - val_accuracy: 0.6233\n",
            "Epoch 24/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.8023 - accuracy: 0.6957 - val_loss: 1.0150 - val_accuracy: 0.6318\n",
            "Epoch 25/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.7766 - accuracy: 0.7087 - val_loss: 1.0273 - val_accuracy: 0.6263\n",
            "Epoch 26/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.7698 - accuracy: 0.7063 - val_loss: 1.0373 - val_accuracy: 0.6211\n",
            "Epoch 27/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.7445 - accuracy: 0.7212 - val_loss: 0.9948 - val_accuracy: 0.6394\n",
            "Epoch 28/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.7325 - accuracy: 0.7262 - val_loss: 1.0404 - val_accuracy: 0.6183\n",
            "Epoch 29/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.7129 - accuracy: 0.7342 - val_loss: 1.0695 - val_accuracy: 0.6283\n",
            "Epoch 30/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.7035 - accuracy: 0.7359 - val_loss: 1.0286 - val_accuracy: 0.6288\n",
            "Epoch 31/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.6863 - accuracy: 0.7467 - val_loss: 1.0345 - val_accuracy: 0.6407\n",
            "Epoch 32/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.6608 - accuracy: 0.7541 - val_loss: 1.0366 - val_accuracy: 0.6422\n",
            "Epoch 33/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.6595 - accuracy: 0.7574 - val_loss: 1.1014 - val_accuracy: 0.6307\n",
            "Epoch 34/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.6478 - accuracy: 0.7593 - val_loss: 1.1187 - val_accuracy: 0.6316\n",
            "Epoch 35/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.6319 - accuracy: 0.7681 - val_loss: 1.1559 - val_accuracy: 0.6390\n",
            "Epoch 36/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.6255 - accuracy: 0.7697 - val_loss: 1.0840 - val_accuracy: 0.6433\n",
            "Epoch 37/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5950 - accuracy: 0.7845 - val_loss: 1.1112 - val_accuracy: 0.6465\n",
            "Epoch 38/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5851 - accuracy: 0.7851 - val_loss: 1.1371 - val_accuracy: 0.6420\n",
            "Epoch 39/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5831 - accuracy: 0.7871 - val_loss: 1.1180 - val_accuracy: 0.6435\n",
            "Epoch 40/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5684 - accuracy: 0.7910 - val_loss: 1.2282 - val_accuracy: 0.6218\n",
            "Epoch 41/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5577 - accuracy: 0.7951 - val_loss: 1.1896 - val_accuracy: 0.6231\n",
            "Epoch 42/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5302 - accuracy: 0.8053 - val_loss: 1.1928 - val_accuracy: 0.6326\n",
            "Epoch 43/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5358 - accuracy: 0.8060 - val_loss: 1.0885 - val_accuracy: 0.6504\n",
            "Epoch 44/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5170 - accuracy: 0.8135 - val_loss: 1.1105 - val_accuracy: 0.6383\n",
            "Epoch 45/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.5014 - accuracy: 0.8150 - val_loss: 1.1340 - val_accuracy: 0.6515\n",
            "Epoch 46/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4911 - accuracy: 0.8230 - val_loss: 1.1524 - val_accuracy: 0.6355\n",
            "Epoch 47/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4823 - accuracy: 0.8248 - val_loss: 1.1289 - val_accuracy: 0.6504\n",
            "Epoch 48/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4819 - accuracy: 0.8254 - val_loss: 1.2137 - val_accuracy: 0.6487\n",
            "Epoch 49/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4696 - accuracy: 0.8300 - val_loss: 1.2306 - val_accuracy: 0.6470\n",
            "Epoch 50/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4470 - accuracy: 0.8384 - val_loss: 1.2265 - val_accuracy: 0.6470\n",
            "Epoch 51/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4372 - accuracy: 0.8445 - val_loss: 1.2145 - val_accuracy: 0.6468\n",
            "Epoch 52/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4351 - accuracy: 0.8427 - val_loss: 1.2738 - val_accuracy: 0.6457\n",
            "Epoch 53/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4196 - accuracy: 0.8488 - val_loss: 1.2917 - val_accuracy: 0.6452\n",
            "Epoch 54/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4146 - accuracy: 0.8501 - val_loss: 1.2789 - val_accuracy: 0.6491\n",
            "Epoch 55/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.4052 - accuracy: 0.8528 - val_loss: 1.2583 - val_accuracy: 0.6396\n",
            "Epoch 56/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3923 - accuracy: 0.8596 - val_loss: 1.2764 - val_accuracy: 0.6502\n",
            "Epoch 57/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3885 - accuracy: 0.8597 - val_loss: 1.2587 - val_accuracy: 0.6411\n",
            "Epoch 58/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3785 - accuracy: 0.8652 - val_loss: 1.3066 - val_accuracy: 0.6494\n",
            "Epoch 59/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3658 - accuracy: 0.8681 - val_loss: 1.3306 - val_accuracy: 0.6607\n",
            "Epoch 60/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3629 - accuracy: 0.8693 - val_loss: 1.3726 - val_accuracy: 0.6657\n",
            "Epoch 61/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3486 - accuracy: 0.8754 - val_loss: 1.4018 - val_accuracy: 0.6613\n",
            "Epoch 62/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3354 - accuracy: 0.8784 - val_loss: 1.3702 - val_accuracy: 0.6478\n",
            "Epoch 63/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.3361 - accuracy: 0.8790 - val_loss: 1.3093 - val_accuracy: 0.6615\n",
            "Epoch 64/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3299 - accuracy: 0.8816 - val_loss: 1.2825 - val_accuracy: 0.6646\n",
            "Epoch 65/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.3047 - accuracy: 0.8914 - val_loss: 1.2601 - val_accuracy: 0.6615\n",
            "Epoch 66/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.3127 - accuracy: 0.8861 - val_loss: 1.4934 - val_accuracy: 0.6576\n",
            "Epoch 67/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.3106 - accuracy: 0.8878 - val_loss: 1.3417 - val_accuracy: 0.6531\n",
            "Epoch 68/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.2978 - accuracy: 0.8918 - val_loss: 1.2907 - val_accuracy: 0.6598\n",
            "Epoch 69/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.2898 - accuracy: 0.8972 - val_loss: 1.4348 - val_accuracy: 0.6644\n",
            "Epoch 70/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.2878 - accuracy: 0.8968 - val_loss: 1.4478 - val_accuracy: 0.6574\n",
            "Epoch 71/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2825 - accuracy: 0.8981 - val_loss: 1.5412 - val_accuracy: 0.6630\n",
            "Epoch 72/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2761 - accuracy: 0.9012 - val_loss: 1.4802 - val_accuracy: 0.6641\n",
            "Epoch 73/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.2646 - accuracy: 0.9056 - val_loss: 1.5838 - val_accuracy: 0.6611\n",
            "Epoch 74/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2686 - accuracy: 0.9038 - val_loss: 1.5990 - val_accuracy: 0.6654\n",
            "Epoch 75/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2617 - accuracy: 0.9060 - val_loss: 1.4702 - val_accuracy: 0.6581\n",
            "Epoch 76/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2555 - accuracy: 0.9081 - val_loss: 1.6074 - val_accuracy: 0.6783\n",
            "Epoch 77/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2563 - accuracy: 0.9066 - val_loss: 1.5174 - val_accuracy: 0.6598\n",
            "Epoch 78/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.2442 - accuracy: 0.9129 - val_loss: 1.5166 - val_accuracy: 0.6596\n",
            "Epoch 79/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2419 - accuracy: 0.9137 - val_loss: 1.5705 - val_accuracy: 0.6504\n",
            "Epoch 80/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2329 - accuracy: 0.9194 - val_loss: 1.5119 - val_accuracy: 0.6568\n",
            "Epoch 81/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2258 - accuracy: 0.9182 - val_loss: 1.6528 - val_accuracy: 0.6518\n",
            "Epoch 82/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.2268 - accuracy: 0.9187 - val_loss: 1.5372 - val_accuracy: 0.6615\n",
            "Epoch 83/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2174 - accuracy: 0.9244 - val_loss: 1.6060 - val_accuracy: 0.6654\n",
            "Epoch 84/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2155 - accuracy: 0.9226 - val_loss: 1.6393 - val_accuracy: 0.6652\n",
            "Epoch 85/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2096 - accuracy: 0.9262 - val_loss: 1.5231 - val_accuracy: 0.6643\n",
            "Epoch 86/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.2040 - accuracy: 0.9262 - val_loss: 1.6575 - val_accuracy: 0.6624\n",
            "Epoch 87/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.2029 - accuracy: 0.9269 - val_loss: 1.5389 - val_accuracy: 0.6611\n",
            "Epoch 88/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1935 - accuracy: 0.9297 - val_loss: 1.8423 - val_accuracy: 0.6656\n",
            "Epoch 89/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.1988 - accuracy: 0.9293 - val_loss: 1.6366 - val_accuracy: 0.6756\n",
            "Epoch 90/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.1954 - accuracy: 0.9303 - val_loss: 1.7080 - val_accuracy: 0.6567\n",
            "Epoch 91/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1902 - accuracy: 0.9321 - val_loss: 1.6815 - val_accuracy: 0.6635\n",
            "Epoch 92/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1829 - accuracy: 0.9334 - val_loss: 1.7924 - val_accuracy: 0.6561\n",
            "Epoch 93/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1832 - accuracy: 0.9348 - val_loss: 1.8068 - val_accuracy: 0.6630\n",
            "Epoch 94/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.1740 - accuracy: 0.9370 - val_loss: 1.7519 - val_accuracy: 0.6665\n",
            "Epoch 95/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1716 - accuracy: 0.9388 - val_loss: 1.8955 - val_accuracy: 0.6657\n",
            "Epoch 96/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.1708 - accuracy: 0.9414 - val_loss: 1.8312 - val_accuracy: 0.6591\n",
            "Epoch 97/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.1672 - accuracy: 0.9388 - val_loss: 1.6959 - val_accuracy: 0.6581\n",
            "Epoch 98/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1753 - accuracy: 0.9366 - val_loss: 1.8084 - val_accuracy: 0.6683\n",
            "Epoch 99/150\n",
            "1351/1351 [==============================] - 35s 26ms/step - loss: 0.1586 - accuracy: 0.9422 - val_loss: 1.6985 - val_accuracy: 0.6657\n",
            "Epoch 100/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1592 - accuracy: 0.9426 - val_loss: 1.8315 - val_accuracy: 0.6598\n",
            "Epoch 101/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1606 - accuracy: 0.9411 - val_loss: 1.8600 - val_accuracy: 0.6743\n",
            "Epoch 102/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1545 - accuracy: 0.9433 - val_loss: 1.8151 - val_accuracy: 0.6683\n",
            "Epoch 103/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1503 - accuracy: 0.9467 - val_loss: 1.8937 - val_accuracy: 0.6728\n",
            "Epoch 104/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1525 - accuracy: 0.9450 - val_loss: 2.0215 - val_accuracy: 0.6594\n",
            "Epoch 105/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1506 - accuracy: 0.9463 - val_loss: 1.7833 - val_accuracy: 0.6746\n",
            "Epoch 106/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1532 - accuracy: 0.9443 - val_loss: 1.9051 - val_accuracy: 0.6541\n",
            "Epoch 107/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1441 - accuracy: 0.9468 - val_loss: 1.8243 - val_accuracy: 0.6681\n",
            "Epoch 108/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1456 - accuracy: 0.9484 - val_loss: 1.7944 - val_accuracy: 0.6728\n",
            "Epoch 109/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1374 - accuracy: 0.9519 - val_loss: 1.8053 - val_accuracy: 0.6622\n",
            "Epoch 110/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1342 - accuracy: 0.9506 - val_loss: 1.9171 - val_accuracy: 0.6687\n",
            "Epoch 111/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1354 - accuracy: 0.9514 - val_loss: 1.8578 - val_accuracy: 0.6626\n",
            "Epoch 112/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1295 - accuracy: 0.9526 - val_loss: 2.0984 - val_accuracy: 0.6659\n",
            "Epoch 113/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1367 - accuracy: 0.9525 - val_loss: 2.0223 - val_accuracy: 0.6659\n",
            "Epoch 114/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1316 - accuracy: 0.9540 - val_loss: 2.0837 - val_accuracy: 0.6635\n",
            "Epoch 115/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1298 - accuracy: 0.9530 - val_loss: 1.9285 - val_accuracy: 0.6659\n",
            "Epoch 116/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1316 - accuracy: 0.9528 - val_loss: 1.9371 - val_accuracy: 0.6750\n",
            "Epoch 117/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1236 - accuracy: 0.9545 - val_loss: 2.0183 - val_accuracy: 0.6661\n",
            "Epoch 118/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.1261 - accuracy: 0.9540 - val_loss: 1.8368 - val_accuracy: 0.6802\n",
            "Epoch 119/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1170 - accuracy: 0.9565 - val_loss: 2.0143 - val_accuracy: 0.6702\n",
            "Epoch 120/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1224 - accuracy: 0.9561 - val_loss: 2.0301 - val_accuracy: 0.6652\n",
            "Epoch 121/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1187 - accuracy: 0.9568 - val_loss: 2.2104 - val_accuracy: 0.6609\n",
            "Epoch 122/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1189 - accuracy: 0.9579 - val_loss: 2.0449 - val_accuracy: 0.6591\n",
            "Epoch 123/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1089 - accuracy: 0.9609 - val_loss: 2.0236 - val_accuracy: 0.6667\n",
            "Epoch 124/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1157 - accuracy: 0.9570 - val_loss: 1.9553 - val_accuracy: 0.6667\n",
            "Epoch 125/150\n",
            "1351/1351 [==============================] - 37s 27ms/step - loss: 0.1131 - accuracy: 0.9590 - val_loss: 2.1095 - val_accuracy: 0.6641\n",
            "Epoch 126/150\n",
            "1351/1351 [==============================] - 37s 27ms/step - loss: 0.1091 - accuracy: 0.9618 - val_loss: 1.9253 - val_accuracy: 0.6663\n",
            "Epoch 127/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1084 - accuracy: 0.9603 - val_loss: 2.0875 - val_accuracy: 0.6694\n",
            "Epoch 128/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1146 - accuracy: 0.9579 - val_loss: 2.0086 - val_accuracy: 0.6613\n",
            "Epoch 129/150\n",
            "1351/1351 [==============================] - 37s 27ms/step - loss: 0.1046 - accuracy: 0.9619 - val_loss: 2.2008 - val_accuracy: 0.6617\n",
            "Epoch 130/150\n",
            "1351/1351 [==============================] - 37s 27ms/step - loss: 0.1078 - accuracy: 0.9600 - val_loss: 1.9388 - val_accuracy: 0.6700\n",
            "Epoch 131/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1071 - accuracy: 0.9616 - val_loss: 2.1824 - val_accuracy: 0.6700\n",
            "Epoch 132/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1076 - accuracy: 0.9613 - val_loss: 2.3090 - val_accuracy: 0.6685\n",
            "Epoch 133/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1042 - accuracy: 0.9621 - val_loss: 1.8823 - val_accuracy: 0.6680\n",
            "Epoch 134/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0978 - accuracy: 0.9654 - val_loss: 2.0965 - val_accuracy: 0.6661\n",
            "Epoch 135/150\n",
            "1351/1351 [==============================] - 36s 26ms/step - loss: 0.0973 - accuracy: 0.9651 - val_loss: 2.2462 - val_accuracy: 0.6743\n",
            "Epoch 136/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.1027 - accuracy: 0.9631 - val_loss: 2.0876 - val_accuracy: 0.6628\n",
            "Epoch 137/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0995 - accuracy: 0.9632 - val_loss: 2.3601 - val_accuracy: 0.6765\n",
            "Epoch 138/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0958 - accuracy: 0.9662 - val_loss: 2.3467 - val_accuracy: 0.6795\n",
            "Epoch 139/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0959 - accuracy: 0.9660 - val_loss: 2.1233 - val_accuracy: 0.6698\n",
            "Epoch 140/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0952 - accuracy: 0.9653 - val_loss: 2.2970 - val_accuracy: 0.6674\n",
            "Epoch 141/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0951 - accuracy: 0.9650 - val_loss: 2.1143 - val_accuracy: 0.6698\n",
            "Epoch 142/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0998 - accuracy: 0.9641 - val_loss: 2.0017 - val_accuracy: 0.6669\n",
            "Epoch 143/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0859 - accuracy: 0.9694 - val_loss: 2.2591 - val_accuracy: 0.6745\n",
            "Epoch 144/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0952 - accuracy: 0.9653 - val_loss: 2.2784 - val_accuracy: 0.6667\n",
            "Epoch 145/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0902 - accuracy: 0.9675 - val_loss: 2.0796 - val_accuracy: 0.6776\n",
            "Epoch 146/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0941 - accuracy: 0.9654 - val_loss: 2.4428 - val_accuracy: 0.6611\n",
            "Epoch 147/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0856 - accuracy: 0.9689 - val_loss: 2.1023 - val_accuracy: 0.6635\n",
            "Epoch 148/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0883 - accuracy: 0.9691 - val_loss: 2.3644 - val_accuracy: 0.6687\n",
            "Epoch 149/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0847 - accuracy: 0.9691 - val_loss: 2.1861 - val_accuracy: 0.6802\n",
            "Epoch 150/150\n",
            "1351/1351 [==============================] - 36s 27ms/step - loss: 0.0862 - accuracy: 0.9679 - val_loss: 2.1138 - val_accuracy: 0.6804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f402da0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVdQUTODCnm3",
        "outputId": "8901ba48-6fd1-41e9-ca97-514c8ba422d6"
      },
      "source": [
        "# x_test =  test_dataset['image']\n",
        "# y_test = test_dataset['label']\n",
        "\n",
        "# x_test = x_test.to_numpy()\n",
        "# y_test = y_test.to_numpy()\n",
        "\n",
        "\n",
        "# x_test = np.stack(x_test,axis=0)\n",
        "# y_test = np.stack(y_test,axis=0)\n",
        "\n",
        "testloss = model.evaluate(x_test, y_test) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(x_train, y_train) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "169/169 [==============================] - 1s 9ms/step - loss: 2.1138 - accuracy: 0.6804\n",
            "Test Loss 2.113839626312256\n",
            "Test Acc: 0.6803855895996094\n",
            "1351/1351 [==============================] - 12s 9ms/step - loss: 0.0531 - accuracy: 0.9794\n",
            "Train Loss 0.0530628077685833\n",
            "Train Acc: 0.9793788194656372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8wQ9IZxWNST"
      },
      "source": [
        ""
      ]
    }
  ]
}